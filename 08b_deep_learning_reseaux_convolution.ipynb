{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_01_reseaux_convolution.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        },
        "id": "X8q03Gq9nLft",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ddd15807-2419-4d0e-dbed-1b62033b1915"
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        },
        "id": "eAGz_rubnLf7",
        "colab_type": "text"
      },
      "source": [
        "# Les réseaux à convolutions\n",
        "\n",
        "Ces réseaux de neurones comprennent deux nouveaux types de couches :\n",
        "    \n",
        "- les couches de convolutions\n",
        "- les couches de pooling\n",
        "\n",
        "http://scs.ryerson.ca/~aharley/vis/conv/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        },
        "id": "d2rZ0llCnLf9",
        "colab_type": "text"
      },
      "source": [
        "# Les couches de convolution\n",
        "\n",
        "La différence fondamentale entre une couche densément connectée et une couche de convolution est la suivante: \n",
        "\n",
        "- les couches denses apprennent des motifs globaux dans leur espace de fonctions en entrée (par exemple, pour un chiffre MNIST, des motifs impliquant tous les pixels), tandis que les couches de convolution apprennent des motifs locaux.\n",
        "\n",
        "Dans le cas des images, des motifs trouvés dans de petites fenêtres 2D des entrées. \n",
        "\n",
        "![image](https://github.com/stat4decision/formation-adway-ml-avr2019/blob/master/images/conv.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        },
        "id": "yXA3QbRxnLf_",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Cette caractéristique clé confère à convnets deux propriétés intéressantes:\n",
        "\n",
        "- Les modèles qu’ils apprennent sont des invariants de traduction.\n",
        "\n",
        "- Ils peuvent apprendre les hiérarchies spatiales des modèles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        },
        "id": "3k7C61yZnLgB",
        "colab_type": "text"
      },
      "source": [
        "Les convolutions sont définies par deux paramètres clés:\n",
        "\n",
        "- Taille des patchs extraits des entrées\n",
        "\n",
        "- Profondeur de la carte de caractéristiques en sortie\n",
        "\n",
        "![image](https://github.com/stat4decision/formation-adway-ml-avr2019/blob/master/images/conv2.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        },
        "id": "QRjtaFFwnLgD",
        "colab_type": "text"
      },
      "source": [
        "# Les couches de pooling\n",
        "\n",
        "Chaque couche MaxPooling2D permet de réduire la taille des cartes de caractéristiaues. \n",
        "\n",
        "C’est le rôle du pooling : sous-échantillonner de manière agressive les cartes de features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "slideshow": {
          "slide_type": "subslide"
        },
        "id": "f2bRdTuxnLgF",
        "colab_type": "text"
      },
      "source": [
        "# Un cas concret\n",
        "\n",
        "Nous allons utiliser notre réseau convnet pour classer les chiffres MNIST.\n",
        "\n",
        "Les 6 lignes de code ci-dessous vous montrent à quoi ressemble un convnet de base. \n",
        "\n",
        "\n",
        "C'est une pile de couches `Conv2D` et` MaxPooling2D`\n",
        "\n",
        "\n",
        "Il est important de noter qu'un convnet prend en entrée des tenseurs de la forme `(image_height, image_width, image_channels)` \n",
        "\n",
        "\n",
        "Dans notre cas, nous allons configurer notre convnet pour traiter des entrées de taille `(28, 28, 1)`, qui est le format des images MNIST. \n",
        "\n",
        "\n",
        "Nous faisons cela via l'argument `input_shape = (28, 28, 1)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        },
        "id": "yu7GDEpwnLgH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "b97a67f4-03bc-42fc-8c8c-0bb0b9303843"
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0705 15:17:11.513831 140575585077120 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0705 15:17:11.565332 140575585077120 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0705 15:17:11.575600 140575585077120 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0705 15:17:11.616221 140575585077120 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        },
        "id": "1ZI4EogbnLgO",
        "colab_type": "text"
      },
      "source": [
        "Voici son architecture :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        },
        "id": "JbAkGY8GnLgQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "424840e8-6a68-4ec6-f528-01e1d8770371"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "=================================================================\n",
            "Total params: 55,744\n",
            "Trainable params: 55,744\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "slideshow": {
          "slide_type": "subslide"
        },
        "id": "uQNgAmlUnLgX",
        "colab_type": "text"
      },
      "source": [
        "Vous pouvez voir que la sortie de chaque couche `Conv2D` et` MaxPooling2D` est un tenseur 3D de forme `(hauteur, largeur, canaux)`. \n",
        "\n",
        "\n",
        "Les dimensions en largeur et en hauteur ont tendance à diminuer à mesure que nous progressons dans le réseau. Le nombre de canaux est contrôlé par le premier argument passé aux couches `Conv2D` (par exemple 32 ou 64).\n",
        "\n",
        "\n",
        "Nous devons donc aplatir nos sorties 3D sur 1D, puis ajouter quelques couches `Dense` au-dessus:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        },
        "id": "eMy6QghgnLgZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        },
        "id": "-VSI7K-onLgf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "2cad09fc-f5cb-48f4-acb1-6ee78b9e0b24"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                36928     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 93,322\n",
            "Trainable params: 93,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        },
        "id": "cG0dmPE0nLgm",
        "colab_type": "text"
      },
      "source": [
        "Maintenant, entraînons notre réseau sur les chiffres du MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        },
        "id": "PMv7zrGDnLgp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "outputId": "b01ec087-924c-4072-9534-8c889d59984f"
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABzOB2TooJcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        },
        "id": "QX3r1EVhnLgv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "5f60578f-9bcf-4ce8-9d5f-c37fe9e035b6"
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=128,validation_data=(test_images,test_labels))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 0.1579 - acc: 0.9418 - val_loss: 0.2720 - val_acc: 0.9043\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.1451 - acc: 0.9459 - val_loss: 0.2519 - val_acc: 0.9155\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.1359 - acc: 0.9496 - val_loss: 0.2876 - val_acc: 0.9095\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.1254 - acc: 0.9529 - val_loss: 0.2958 - val_acc: 0.9076\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.1167 - acc: 0.9573 - val_loss: 0.2787 - val_acc: 0.9150\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.1088 - acc: 0.9591 - val_loss: 0.3043 - val_acc: 0.9117\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.1005 - acc: 0.9621 - val_loss: 0.3001 - val_acc: 0.9164\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0938 - acc: 0.9646 - val_loss: 0.3278 - val_acc: 0.9133\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0877 - acc: 0.9675 - val_loss: 0.3675 - val_acc: 0.9091\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.0812 - acc: 0.9698 - val_loss: 0.3346 - val_acc: 0.9096\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fda03e7aef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        },
        "id": "LUvlQR-4nLg0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "458a1689-d58b-4eaf-83d4-f8c3ed6f786d"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 89us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        },
        "id": "3duwtRivnLg7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20e19bbc-530d-4a26-b082-4ebfc80f8a7e"
      },
      "source": [
        "test_acc"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9082"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8in9MG1puQy-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "aaa45ca1-b6aa-41fe-ebc8-f635b05be758"
      },
      "source": [
        "model.predict(test_images[10,].reshape(1,28,28,1))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.8491994e-08, 9.3746379e-11, 2.0429505e-05, 1.4432024e-11,\n",
              "        9.9977046e-01, 2.2831218e-11, 2.0900051e-04, 8.7442168e-13,\n",
              "        5.0325111e-10, 6.8893766e-11]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNOfUMPiuqyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import imageio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyU8eEQ_uuds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUUu_i2uu0R2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "ee64969c-dad3-4b23-9a7e-0d09d04edfc6"
      },
      "source": [
        "plt.imshow(test_images[10,].reshape(28,28))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd9b62dc748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zbg0fivvHT0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "50caf13d-933a-4a34-b2c0-478aef964a70"
      },
      "source": [
        "test_labels[10]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}